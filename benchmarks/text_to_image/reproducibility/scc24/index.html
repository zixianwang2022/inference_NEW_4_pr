
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../sdxl/">
      
      
        <link rel="next" href="../../../object_detection/retinanet/">
      
      
      <link rel="icon" href="../../../../img/logo_v2.svg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.44">
    
    
      
        <title>SCC24 - MLPerf Inference Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.0253249f.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="green">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#text-to-image-with-stable-diffusion-for-student-cluster-competition-2024" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="MLPerf Inference Documentation" class="md-header__button md-logo" aria-label="MLPerf Inference Documentation" data-md-component="logo">
      
  <img src="../../../../img/logo_v2.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            MLPerf Inference Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              SCC24
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/mlcommons/inference" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../.." class="md-tabs__link">
          
  
    
  
  Home

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../install/" class="md-tabs__link">
          
  
    
  
  Install CM

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../submission/" class="md-tabs__link">
          
  
    
  
  Submission

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../changelog/" class="md-tabs__link">
          
  
    
  
  Release Notes

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="MLPerf Inference Documentation" class="md-nav__button md-logo" aria-label="MLPerf Inference Documentation" data-md-component="logo">
      
  <img src="../../../../img/logo_v2.svg" alt="logo">

    </a>
    MLPerf Inference Documentation
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mlcommons/inference" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../.." class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Home
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_1" id="__nav_1_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Home
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1_2" >
        
          
          <label class="md-nav__link" for="__nav_1_2" id="__nav_1_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Image Classification
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_2">
            <span class="md-nav__icon md-icon"></span>
            Image Classification
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../image_classification/resnet50/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ResNet50
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_3" checked>
        
          
          <label class="md-nav__link" for="__nav_1_3" id="__nav_1_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Text to Image
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1_3">
            <span class="md-nav__icon md-icon"></span>
            Text to Image
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_3_1" checked>
        
          
          <label class="md-nav__link" for="__nav_1_3_1" id="__nav_1_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Stable Diffusion
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_1_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1_3_1">
            <span class="md-nav__icon md-icon"></span>
            Stable Diffusion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sdxl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Run Commands
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_3_1_2" checked>
        
          
          <label class="md-nav__link" for="__nav_1_3_1_2" id="__nav_1_3_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reproducibility
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_1_3_1_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            Reproducibility
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    SCC24
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    SCC24
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scoring" class="md-nav__link">
    <span class="md-ellipsis">
      Scoring
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#artifacts-to-submit-to-the-scc-committee" class="md-nav__link">
    <span class="md-ellipsis">
      Artifacts to submit to the SCC committee
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scc-interview" class="md-nav__link">
    <span class="md-ellipsis">
      SCC interview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#run-commands" class="md-nav__link">
    <span class="md-ellipsis">
      Run Commands
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mlperf-reference-implementation-in-python" class="md-nav__link">
    <span class="md-ellipsis">
      MLPerf Reference Implementation in Python
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MLPerf Reference Implementation in Python">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#datacenter-category" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pytorch-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Pytorch framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pytorch framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rocm-device" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ROCm device">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#native-environment" class="md-nav__link">
    <span class="md-ellipsis">
      Native Environment
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setup-a-virtual-environment-for-python" class="md-nav__link">
    <span class="md-ellipsis">
      # Setup a virtual environment for Python
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-estimation-for-offline-scenario" class="md-nav__link">
    <span class="md-ellipsis">
      # Performance Estimation for Offline Scenario
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline" class="md-nav__link">
    <span class="md-ellipsis">
      Offline
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CUDA device">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#docker-environment" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Environment
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-container-build-and-performance-estimation-for-offline-scenario" class="md-nav__link">
    <span class="md-ellipsis">
      # Docker Container Build and Performance Estimation for Offline Scenario
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_1" class="md-nav__link">
    <span class="md-ellipsis">
      Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#native-environment_1" class="md-nav__link">
    <span class="md-ellipsis">
      Native Environment
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setup-a-virtual-environment-for-python_1" class="md-nav__link">
    <span class="md-ellipsis">
      # Setup a virtual environment for Python
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-estimation-for-offline-scenario_1" class="md-nav__link">
    <span class="md-ellipsis">
      # Performance Estimation for Offline Scenario
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_2" class="md-nav__link">
    <span class="md-ellipsis">
      Offline
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#nvidia-mlperf-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Nvidia MLPerf Implementation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Nvidia MLPerf Implementation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#datacenter-category_1" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorrt-framework" class="md-nav__link">
    <span class="md-ellipsis">
      TensorRT framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TensorRT framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-device_1" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CUDA device">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#docker-environment_1" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Environment
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-container-build-and-performance-estimation-for-offline-scenario_1" class="md-nav__link">
    <span class="md-ellipsis">
      # Docker Container Build and Performance Estimation for Offline Scenario
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_3" class="md-nav__link">
    <span class="md-ellipsis">
      Offline
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#submission-commands" class="md-nav__link">
    <span class="md-ellipsis">
      Submission Commands
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Submission Commands">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#generate-actual-submission-tree" class="md-nav__link">
    <span class="md-ellipsis">
      Generate actual submission tree
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#push-results-to-github" class="md-nav__link">
    <span class="md-ellipsis">
      Push Results to GitHub
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1_4" >
        
          
          <label class="md-nav__link" for="__nav_1_4" id="__nav_1_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Object Detection
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_4">
            <span class="md-nav__icon md-icon"></span>
            Object Detection
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../object_detection/retinanet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RetinaNet
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1_5" >
        
          
          <label class="md-nav__link" for="__nav_1_5" id="__nav_1_5_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Medical Imaging
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_5">
            <span class="md-nav__icon md-icon"></span>
            Medical Imaging
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../medical_imaging/3d-unet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3d-unet
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1_6" >
        
          
          <label class="md-nav__link" for="__nav_1_6" id="__nav_1_6_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Language Processing
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_6">
            <span class="md-nav__icon md-icon"></span>
            Language Processing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1_6_1" >
        
          
          <label class="md-nav__link" for="__nav_1_6_1" id="__nav_1_6_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Bert-Large
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_1_6_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_6_1">
            <span class="md-nav__icon md-icon"></span>
            Bert-Large
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../language/bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Run Commands
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1_6_1_2" >
        
          
          <label class="md-nav__link" for="__nav_1_6_1_2" id="__nav_1_6_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reproducibility
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_1_6_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_6_1_2">
            <span class="md-nav__icon md-icon"></span>
            Reproducibility
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../language/reproducibility/indyscc24-bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IndySCC24
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../language/gpt-j/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GPT-J
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../language/llama2-70b/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LLAMA2-70B
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../language/mixtral-8x7b/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MIXTRAL-8x7B
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1_7" >
        
          
          <label class="md-nav__link" for="__nav_1_7" id="__nav_1_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Recommendation
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_7">
            <span class="md-nav__icon md-icon"></span>
            Recommendation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../recommendation/dlrm-v2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DLRM-v2
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../install/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Install CM
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Install CM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../submission/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Submission
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Submission
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../changelog/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Release Notes
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Release Notes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../changelog/changelog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Changelog
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scoring" class="md-nav__link">
    <span class="md-ellipsis">
      Scoring
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#artifacts-to-submit-to-the-scc-committee" class="md-nav__link">
    <span class="md-ellipsis">
      Artifacts to submit to the SCC committee
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scc-interview" class="md-nav__link">
    <span class="md-ellipsis">
      SCC interview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#run-commands" class="md-nav__link">
    <span class="md-ellipsis">
      Run Commands
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mlperf-reference-implementation-in-python" class="md-nav__link">
    <span class="md-ellipsis">
      MLPerf Reference Implementation in Python
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MLPerf Reference Implementation in Python">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#datacenter-category" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pytorch-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Pytorch framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pytorch framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rocm-device" class="md-nav__link">
    <span class="md-ellipsis">
      ROCm device
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ROCm device">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#native-environment" class="md-nav__link">
    <span class="md-ellipsis">
      Native Environment
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setup-a-virtual-environment-for-python" class="md-nav__link">
    <span class="md-ellipsis">
      # Setup a virtual environment for Python
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-estimation-for-offline-scenario" class="md-nav__link">
    <span class="md-ellipsis">
      # Performance Estimation for Offline Scenario
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline" class="md-nav__link">
    <span class="md-ellipsis">
      Offline
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CUDA device">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#docker-environment" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Environment
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-container-build-and-performance-estimation-for-offline-scenario" class="md-nav__link">
    <span class="md-ellipsis">
      # Docker Container Build and Performance Estimation for Offline Scenario
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_1" class="md-nav__link">
    <span class="md-ellipsis">
      Offline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#native-environment_1" class="md-nav__link">
    <span class="md-ellipsis">
      Native Environment
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setup-a-virtual-environment-for-python_1" class="md-nav__link">
    <span class="md-ellipsis">
      # Setup a virtual environment for Python
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-estimation-for-offline-scenario_1" class="md-nav__link">
    <span class="md-ellipsis">
      # Performance Estimation for Offline Scenario
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_2" class="md-nav__link">
    <span class="md-ellipsis">
      Offline
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#nvidia-mlperf-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Nvidia MLPerf Implementation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Nvidia MLPerf Implementation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#datacenter-category_1" class="md-nav__link">
    <span class="md-ellipsis">
      Datacenter category
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Datacenter category">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorrt-framework" class="md-nav__link">
    <span class="md-ellipsis">
      TensorRT framework
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TensorRT framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-device_1" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA device
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CUDA device">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#docker-environment_1" class="md-nav__link">
    <span class="md-ellipsis">
      Docker Environment
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#docker-container-build-and-performance-estimation-for-offline-scenario_1" class="md-nav__link">
    <span class="md-ellipsis">
      # Docker Container Build and Performance Estimation for Offline Scenario
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline_3" class="md-nav__link">
    <span class="md-ellipsis">
      Offline
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#submission-commands" class="md-nav__link">
    <span class="md-ellipsis">
      Submission Commands
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Submission Commands">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#generate-actual-submission-tree" class="md-nav__link">
    <span class="md-ellipsis">
      Generate actual submission tree
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#push-results-to-github" class="md-nav__link">
    <span class="md-ellipsis">
      Push Results to GitHub
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="text-to-image-with-stable-diffusion-for-student-cluster-competition-2024">Text-to-Image with Stable Diffusion for Student Cluster Competition 2024</h1>
<h2 id="introduction">Introduction</h2>
<p>This guide is designed for the <a href="https://sc24.supercomputing.org/students/student-cluster-competition/">Student Cluster Competition 2024</a> to walk participants through running and optimizing the <a href="https://arxiv.org/abs/1911.02549">MLPerf Inference Benchmark</a> using <a href="https://github.com/mlcommons/inference/tree/master/text_to_image#supported-models">Stable Diffusion XL 1.0</a> across various software and hardware configurations. The goal is to maximize system throughput (measured in samples per second) without compromising accuracy. Since the model performs poorly on CPUs, it is essential to run it on GPUs.</p>
<p>For a valid MLPerf inference submission, two types of runs are required: a performance run and an accuracy run. In this competition, we focus on the <code>Offline</code> scenario, where throughput is the key metric—higher values are better. The official MLPerf inference benchmark for Stable Diffusion XL requires processing a minimum of 5,000 samples in both performance and accuracy modes using the COCO 2014 dataset. However, for SCC, we have reduced this and we also have two variants. <code>scc-base</code> variant has dataset size reduced to 50 samples, making it possible to complete both performance and accuracy runs in approximately 5-10 minutes. <code>scc-main</code> variant has dataset size of 500 and running it will fetch extra points as compared to running just the base variant. Setting up for Nvidia GPUs may take 2-3 hours but can be done offline. Your final output will be a tarball (<code>mlperf_submission.tar.gz</code>) containing MLPerf-compatible results, which you will submit to the SCC organizers for scoring.</p>
<h2 id="scoring">Scoring</h2>
<p>In the SCC, your first objective will be to run <code>scc-base</code> variant for reference (unoptimized) Python implementation or a vendor-provided version (such as Nvidia's) of the MLPerf inference benchmark to secure a baseline score.</p>
<p>Once the initial run is successful, you'll have the opportunity to optimize the benchmark further by maximizing system utilization, applying quantization techniques, adjusting ML frameworks, experimenting with batch sizes, and more, all of which can earn you additional points.</p>
<p>Since vendor implementations of the MLPerf inference benchmark vary and are often limited to single-node benchmarking, teams will compete within their respective hardware categories (e.g., Nvidia GPUs, AMD GPUs). Points will be awarded based on the throughput achieved on your system.</p>
<p>Additionally, significant bonus points will be awarded if your team enhances an existing implementation, adds support for new hardware (such as an unsupported GPU), enables multi-node execution, or adds/extends scripts to <a href="https://github.com/mlcommons/cm4mlops/tree/main/script">cm4mlops repository</a> supporting new devices, frameworks, implementations etc. All improvements must be made publicly available under the Apache 2.0 license and submitted alongside your results to the SCC committee to earn these bonus points, contributing to the MLPerf community.</p>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>Both MLPerf and CM automation are evolving projects.
If you encounter issues or have questions, please submit them <a href="https://github.com/mlcommons/cm4mlops/issues">here</a></p>
</div>
<h2 id="artifacts-to-submit-to-the-scc-committee">Artifacts to submit to the SCC committee</h2>
<p>You will need to submit the following files:</p>
<ul>
<li><code>mlperf_submission.run</code> - CM commands to run MLPerf inference benchmark saved to this file.</li>
<li><code>mlperf_submission.md</code> - description of your platform and some highlights of the MLPerf benchmark execution.</li>
<li><code>&lt;Team Name&gt;</code> under which results are pushed to the github repository. </li>
</ul>
<h2 id="scc-interview">SCC interview</h2>
<p>You are encouraged to highlight and explain the obtained MLPerf inference throughput on your system
and describe any improvements and extensions to this benchmark (such as adding new hardware backend
or supporting multi-node execution) useful for the community and <a href="https://mlcommons.org">MLCommons</a>.</p>
<h2 id="run-commands">Run Commands</h2>
<div class="tabbed-set tabbed-alternate" data-tabs="1:2"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">MLCommons-Python</label><label for="__tabbed_1_2">Nvidia</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h2 id="mlperf-reference-implementation-in-python">MLPerf Reference Implementation in Python</h2>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<ul>
<li>MLCommons reference implementations are only meant to provide a rules compliant reference implementation for the submitters and in most cases are not best performing. If you want to benchmark any system, it is advisable to use the vendor MLPerf implementation for that system like Nvidia, Intel etc.</li>
</ul>
</div>
<p>SDXL</p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:1"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">datacenter</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h3 id="datacenter-category">Datacenter category</h3>
<p>In the datacenter category, sdxl has Offline scenarios and all the scenarios are mandatory for a closed division submission.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="3:1"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio" /><div class="tabbed-labels"><label for="__tabbed_3_1">Pytorch</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h4 id="pytorch-framework">Pytorch framework</h4>
<div class="tabbed-set tabbed-alternate" data-tabs="4:2"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio" /><input id="__tabbed_4_2" name="__tabbed_4" type="radio" /><div class="tabbed-labels"><label for="__tabbed_4_1">ROCm</label><label for="__tabbed_4_2">CUDA</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h5 id="rocm-device">ROCm device</h5>
<p><details>
<summary>Please click here to see the minimum system requirements for running the benchmark</summary></p>
<ul>
<li><strong>Disk Space</strong>: 50GB</li>
</ul>
</details>
<div class="tabbed-set tabbed-alternate" data-tabs="5:1"><input checked="checked" id="__tabbed_5_1" name="__tabbed_5" type="radio" /><div class="tabbed-labels"><label for="__tabbed_5_1">Native</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="native-environment">Native Environment</h6>
<p>Please refer to the <a href="/inference/install/">installation page</a> to install CM for running the automated benchmark commands.</p>
<h6 id="setup-a-virtual-environment-for-python"># Setup a virtual environment for Python</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>install,python-venv<span class="w"> </span>--name<span class="o">=</span>mlperf
<span class="nb">export</span><span class="w"> </span><span class="nv">CM_SCRIPT_EXTRA_CMD</span><span class="o">=</span><span class="s2">&quot;--adr.python.name=mlperf&quot;</span>
</code></pre></div>
<h6 id="performance-estimation-for-offline-scenario"># Performance Estimation for Offline Scenario</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_r4.1-dev,_short,_scc24-base<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>sdxl<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution_mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--precision<span class="o">=</span>float16
</code></pre></div>
The above command should do a test run of Offline scenario and record the estimated offline_target_qps.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="6:1"><input checked="checked" id="__tabbed_6_1" name="__tabbed_6" type="radio" /><div class="tabbed-labels"><label for="__tabbed_6_1">Offline</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline">Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_r4.1-dev,_short,_scc24-base<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>sdxl<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution_mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>rocm<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet<span class="w"> </span>--precision<span class="o">=</span>float16
</code></pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h5 id="cuda-device">CUDA device</h5>
<p><details>
<summary>Please click here to see the minimum system requirements for running the benchmark</summary></p>
<ul>
<li>
<p><strong>Device Memory</strong>: 24GB(fp32), 16GB(fp16)</p>
</li>
<li>
<p><strong>Disk Space</strong>: 50GB</p>
</li>
</ul>
</details>
<div class="tabbed-set tabbed-alternate" data-tabs="7:2"><input checked="checked" id="__tabbed_7_1" name="__tabbed_7" type="radio" /><input id="__tabbed_7_2" name="__tabbed_7" type="radio" /><div class="tabbed-labels"><label for="__tabbed_7_1">Docker</label><label for="__tabbed_7_2">Native</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="docker-environment">Docker Environment</h6>
<p>Please refer to the <a href="/inference/install/">installation page</a> to install CM for running the automated benchmark commands.</p>
<h6 id="docker-container-build-and-performance-estimation-for-offline-scenario"># Docker Container Build and Performance Estimation for Offline Scenario</h6>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<ul>
<li><code>--env.CM_MLPERF_MODEL_SDXL_DOWNLOAD_TO_HOST=yes</code> option can be used to download the model on the host so that it can be reused across different container lanuches. </li>
</ul>
</div>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_r4.1-dev,_short,_scc24-base<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>sdxl<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution_mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--precision<span class="o">=</span>float16
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for the Offline scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo=&lt;Custom CM GitHub repo URL in username@repo format&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cm_repo_branch=&lt;Custom CM GitHub repo Branch&gt;</code>: to checkout a custom branch of the cloned cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build
</details></p>
</li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="8:1"><input checked="checked" id="__tabbed_8_1" name="__tabbed_8" type="radio" /><div class="tabbed-labels"><label for="__tabbed_8_1">Offline</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_1">Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_r4.1-dev,_short,_scc24-base<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>sdxl<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution_mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet<span class="w"> </span>--precision<span class="o">=</span>float16
</code></pre></div>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h6 id="native-environment_1">Native Environment</h6>
<p>Please refer to the <a href="/inference/install/">installation page</a> to install CM for running the automated benchmark commands.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<ul>
<li>It is advisable to use the commands in the Docker tab for CUDA. Run the below native command only if you are already on a CUDA setup with cuDNN and TensorRT installed.</li>
</ul>
</div>
<h6 id="setup-a-virtual-environment-for-python_1"># Setup a virtual environment for Python</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>install,python-venv<span class="w"> </span>--name<span class="o">=</span>mlperf
<span class="nb">export</span><span class="w"> </span><span class="nv">CM_SCRIPT_EXTRA_CMD</span><span class="o">=</span><span class="s2">&quot;--adr.python.name=mlperf&quot;</span>
</code></pre></div>
<h6 id="performance-estimation-for-offline-scenario_1"># Performance Estimation for Offline Scenario</h6>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_r4.1-dev,_short,_scc24-base<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>sdxl<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution_mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--precision<span class="o">=</span>float16
</code></pre></div>
The above command should do a test run of Offline scenario and record the estimated offline_target_qps.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="9:1"><input checked="checked" id="__tabbed_9_1" name="__tabbed_9" type="radio" /><div class="tabbed-labels"><label for="__tabbed_9_1">Offline</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_2">Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_r4.1-dev,_short,_scc24-base<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>sdxl<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>reference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>pytorch<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution_mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet<span class="w"> </span>--precision<span class="o">=</span>float16
</code></pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="tabbed-block">
<h2 id="nvidia-mlperf-implementation">Nvidia MLPerf Implementation</h2>
<p>SDXL</p>
<div class="tabbed-set tabbed-alternate" data-tabs="10:1"><input checked="checked" id="__tabbed_10_1" name="__tabbed_10" type="radio" /><div class="tabbed-labels"><label for="__tabbed_10_1">datacenter</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h3 id="datacenter-category_1">Datacenter category</h3>
<p>In the datacenter category, sdxl has Offline scenarios and all the scenarios are mandatory for a closed division submission.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="11:1"><input checked="checked" id="__tabbed_11_1" name="__tabbed_11" type="radio" /><div class="tabbed-labels"><label for="__tabbed_11_1">TensorRT</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h4 id="tensorrt-framework">TensorRT framework</h4>
<div class="tabbed-set tabbed-alternate" data-tabs="12:1"><input checked="checked" id="__tabbed_12_1" name="__tabbed_12" type="radio" /><div class="tabbed-labels"><label for="__tabbed_12_1">CUDA</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h5 id="cuda-device_1">CUDA device</h5>
<p><details>
<summary>Please click here to see the minimum system requirements for running the benchmark</summary></p>
<ul>
<li>
<p><strong>Device Memory</strong>: 16GB</p>
</li>
<li>
<p><strong>Disk Space</strong>: 50GB</p>
</li>
</ul>
</details>
<div class="tabbed-set tabbed-alternate" data-tabs="13:1"><input checked="checked" id="__tabbed_13_1" name="__tabbed_13" type="radio" /><div class="tabbed-labels"><label for="__tabbed_13_1">Docker</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="docker-environment_1">Docker Environment</h6>
<p>Please refer to the <a href="/inference/install/">installation page</a> to install CM for running the automated benchmark commands.</p>
<h6 id="docker-container-build-and-performance-estimation-for-offline-scenario_1"># Docker Container Build and Performance Estimation for Offline Scenario</h6>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<ul>
<li><code>--env.CM_MLPERF_MODEL_SDXL_DOWNLOAD_TO_HOST=yes</code> option can be used to download the model on the host so that it can be reused across different container lanuches. </li>
</ul>
</div>
<p><div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_find-performance,_r4.1-dev,_short,_scc24-base<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>sdxl<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorrt<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution_mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w">  </span><span class="se">\</span>
<span class="w">   </span>--docker<span class="w"> </span>--quiet
</code></pre></div>
The above command should get you to an interactive shell inside the docker container and do a quick test run for the Offline scenario. Once inside the docker container please do the below commands to do the accuracy + performance runs for the Offline scenario.</p>
<p><details>
<summary> Please click here to see more options for the docker launch </summary></p>
<ul>
<li>
<p><code>--docker_cm_repo=&lt;Custom CM GitHub repo URL in username@repo format&gt;</code>: to use a custom fork of cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cm_repo_branch=&lt;Custom CM GitHub repo Branch&gt;</code>: to checkout a custom branch of the cloned cm4mlops repository inside the docker image</p>
</li>
<li>
<p><code>--docker_cache=no</code>: to not use docker cache during the image build</p>
</li>
<li><code>--gpu_name=&lt;Name of the GPU&gt;</code> : The GPUs with supported configs in CM are <code>orin</code>, <code>rtx_4090</code>, <code>rtx_a6000</code>, <code>rtx_6000_ada</code>, <code>l4</code>, <code>t4</code>and <code>a100</code>. For other GPUs, default configuration as per the GPU memory will be used.
</details></li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="14:1"><input checked="checked" id="__tabbed_14_1" name="__tabbed_14" type="radio" /><div class="tabbed-labels"><label for="__tabbed_14_1">Offline</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<h6 id="offline_3">Offline</h6>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>run-mlperf,inference,_r4.1-dev,_short,_scc24-base<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--model<span class="o">=</span>sdxl<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--implementation<span class="o">=</span>nvidia<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--framework<span class="o">=</span>tensorrt<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--scenario<span class="o">=</span>Offline<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--execution_mode<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--device<span class="o">=</span>cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet<span class="w"> </span>
</code></pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>Once the above run is successful, you can change <code>_scc24-base</code> to <code>_scc24-main</code> to run the main variant.</p>
</div>
<h2 id="submission-commands">Submission Commands</h2>
<h3 id="generate-actual-submission-tree">Generate actual submission tree</h3>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>generate,inference,submission<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--clean<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--preprocess_submission<span class="o">=</span>yes<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--run-checker<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--tar<span class="o">=</span>yes<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--env.CM_TAR_OUTFILE<span class="o">=</span>submission.tar.gz<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--division<span class="o">=</span>open<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--category<span class="o">=</span>datacenter<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--env.CM_DETERMINE_MEMORY_CONFIGURATION<span class="o">=</span>yes<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--run_style<span class="o">=</span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--adr.submission-checker.tags<span class="o">=</span>_short-run<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--submitter<span class="o">=</span>&lt;Team<span class="w"> </span>Name&gt;
</code></pre></div>
<ul>
<li>Use <code>--hw_name="My system name"</code> to give a meaningful system name.</li>
</ul>
<h3 id="push-results-to-github">Push Results to GitHub</h3>
<p>Fork the <code>mlperf-inference-results-scc24</code> branch of the repository URL at <a href="https://github.com/mlcommons/cm4mlperf-inference">https://github.com/mlcommons/cm4mlperf-inference</a>. </p>
<p>Run the following command after <strong>replacing <code>--repo_url</code> with your GitHub fork URL</strong>.</p>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span>--tags<span class="o">=</span>push,github,mlperf,inference,submission<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--repo_url<span class="o">=</span>https://github.com/&lt;myfork&gt;/cm4mlperf-inference<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--repo_branch<span class="o">=</span>mlperf-inference-results-scc24<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--commit_message<span class="o">=</span><span class="s2">&quot;Results on system &lt;HW Name&gt;&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--quiet
</code></pre></div>
<p>Once uploaded give a Pull Request to the origin repository. Github action will be running there and once 
finished you can see your submitted results at <a href="https://docs.mlcommons.org/cm4mlperf-inference">https://docs.mlcommons.org/cm4mlperf-inference</a>.</p>







  
  




  



                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["content.tabs.link", "content.code.copy", "navigation.expand", "navigation.sections", "navigation.indexes", "navigation.instant", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "toc.follow"], "search": "../../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>